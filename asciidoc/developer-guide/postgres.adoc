= PostgreSQL

[[useful_queries]]
== Useful Queries

=== Rename key in jsonb array
The example is not aiming at perfomance.

Considering the following table :
[source,sql]
----
CREATE TABLE organism (id integer, determinations jsonb);
----

With jsonb array in the `determinations` column:
[source,sql]
----
INSERT INTO organism VALUES (1, '[
{
  "scientificNameSource": "GNA",
  "isPrimary": true,
  "isFileAs": true
},
{
  "scientificNameSource": "GNA",
  "isPrimary": false,
  "isFileAs": false
}
]');
----

We want to rename the key `isFileAs` to `isFiledAs`:
[source,sql]
----
-- unwrap the array and extract the value
WITH subquery AS (
  SELECT id, item, item -> 'isFileAs' as att_value
  FROM organism, jsonb_array_elements(determinations) as item
),
-- remove the old attribute and create the new one with the value
-- reconstruct the array by grouping by id
subquery2 AS (
  select id, json_agg(jsonb_set(item-'isFileAs', '{isFiledAs}', att_value)) as updated_jsonb from subquery
  GROUP BY id
)
 
UPDATE organism
  SET determinations = updated_jsonb
  FROM subquery2
  WHERE organism.id = subquery2.id;
----

[[restore_backup]]
== Restore Backup (DINA Local Deployment)

These instructions are designed for core dump backups; other types of backup will require a different solution for restoring.

1. Move your database dump file

Move your DINA dump `.sql.gz` file into the `dina-local-deployment` repository.

[start=2]
2. Remove Existing Docker Volumes

It's recommended to delete your existing DINA Docker volumes to avoid conflicts with the existing data. You can use this command or use the VS Code Docker extension to remove the existing volumes.

[source,sh]
----
./start_stop_dina.sh down --volumes
----

[start=3]
3. Extract and make changes to the file

Depending on what version of PostgreSQL the dump was generated from, the dump might not be compatible with your current version. To get around this, you can extract the `.gz` file and run this `sed` command to convert it:

[source,sh]
----
gzip -d dina_dump.sql.gz
sed -i "s/ LOCALE = 'en_US\.utf8'//g" dina_dump.sql
----

The database dump might also contain database names like "v0_agent", it can be converted to what local deployment expects using:

[source,sh]
----
sed -i "s/v0_//g" dina_dump.sql
----

[start=4]
4. Change the database connection settings if needed

In the `dina-compose.local.yml` file you will need to change the `spring.datasource.url` for each of the APIs you will need to use:

[source,yml]
----
spring.datasource.url: jdbc:postgresql://dina-db/v0_object_store?currentSchema=object_store
----

In the example above, it was changed from `object_store` to `v0_object_store` to match the dump. That's if you did not convert it using the sed command, otherwise it can remain the same.

[start=5]
5. Start up the application

[source,sh]
----
./start_stop_dina.sh up -d
----

Once the `dina-db` container starts, the `init-db` container will set up the database. Once the application has loaded with the empty database, the database dump can be copied over to it:

[source,sh]
----
docker cp ./dina_dump.sql dina-local-deployment-dina-db-1:/home/dina_dump.sql
----

[start=6]
6. Restore the dump file

With the file copied over to the home folder, you can now run this command to import the file into the Postgresql database:

[source,sh]
----
docker exec -it dina-local-deployment-dina-db-1 psql -f /home/dina_dump.sql -d dina -U pguser
----

At this point, you should be able to log in to the application and verify that the backup worked correctly.
